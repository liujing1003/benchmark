import torch
import torch.nn as nn
import math
from torch.autograd import Variable


def conv3x3(in_planes, out_planes, stride=1):
    "3x3 convolution with padding"
    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,
                     padding=1, bias=False)


# Compute Covariance Matrix
def covariance(A):
    batchSize = A.size(0)
    dim = A.size(1)
    N = A.size(2)  # N features
    P = Variable(torch.FloatTensor(batchSize, dim, dim)).cuda()

    for i in range(0, batchSize):
        I = Variable(torch.eye(N)).cuda()
        ones_vec = Variable(torch.ones(N, 1)).cuda()
        _I = 1.0 / N * (I - 1.0 / N * torch.matmul(ones_vec, torch.t(ones_vec)))
        P[i] = torch.matmul(torch.matmul(A[i], _I), torch.t(A[i]))

    return P


# Get the upper triangular mask of matirx
def triu_mask(value):
    n = value.size(-1)
    coords = value.data.new(n)
    torch.arange(float(0), float(n), out=coords)
    return coords >= coords.view(n, 1)


# Get the upper triangular matrix of a given matrix
def upper_triangular(A):
    batchSize = A.size(0)
    dim = A.size(1)
    N = A.size(2)   # N features
    U = Variable(torch.FloatTensor(batchSize, int(dim*(dim+1)/2))).cuda()
    for i in range(0, batchSize):
        U[i] = A[i][triu_mask(A[i])]

    return U


# Compute error
def compute_error(A, sA):
    normA = torch.sqrt(torch.sum(torch.sum(A * A, dim=1), dim=1))
    error = A - torch.bmm(sA, sA)
    error = torch.sqrt((error * error).sum(dim=1).sum(dim=1)) / normA
    return torch.mean(error)


def sqrt_newton_schulz_autograd(A, numIters, dtype):
    batchSize = A.data.shape[0]
    dim = A.data.shape[1]
    normA = A.mul(A).sum(dim=1).sum(dim=1).sqrt()
    Y = A.div(normA.view(batchSize, 1, 1).expand_as(A));
    I = Variable(torch.eye(dim, dim).view(1, dim, dim).
                 repeat(batchSize, 1, 1).type(dtype), requires_grad=False).cuda()
    Z = Variable(torch.eye(dim, dim).view(1, dim, dim).
                 repeat(batchSize, 1, 1).type(dtype), requires_grad=False).cuda()

    for i in range(numIters):
        T = 0.5 * (3.0 * I - Z.bmm(Y))
        Y = Y.bmm(T)
        Z = T.bmm(Z)
    sA = Y * torch.sqrt(normA).view(batchSize, 1, 1).expand_as(A)
    error = compute_error(A, sA)
    return sA, error
